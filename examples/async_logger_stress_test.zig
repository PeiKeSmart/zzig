const std = @import("std");
const AsyncLogger = @import("zzig").AsyncLogger;

/// æ¨¡æ‹Ÿç™¾ä¸‡çº§è®¾å¤‡çš„é«˜è´Ÿè½½æ—¥å¿—æµ‹è¯•
pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("\n=== å¼‚æ­¥æ—¥å¿— - ç™¾ä¸‡çº§è®¾å¤‡å‹åŠ›æµ‹è¯• ===\n\n", .{});

    // é…ç½®ï¼šæ›´å¤§çš„é˜Ÿåˆ—å®¹é‡ï¼Œé€‚åº”é«˜å¹¶å‘
    const config = AsyncLogger.AsyncLoggerConfig{
        .queue_capacity = 16384, // 16K æ¶ˆæ¯ç¼“å†²
        .idle_sleep_us = 50, // æ›´çŸ­çš„ä¼‘çœ æ—¶é—´
        .global_level = .info,
        .enable_drop_counter = true,
    };

    const logger = try AsyncLogger.AsyncLogger.init(allocator, config);
    defer logger.deinit();

    std.debug.print("ğŸ“Š æµ‹è¯•é…ç½®:\n", .{});
    std.debug.print("   é˜Ÿåˆ—å®¹é‡: {d}\n", .{config.queue_capacity});
    std.debug.print("   æ¨¡æ‹Ÿè®¾å¤‡æ•°: 100ä¸‡\n", .{});
    std.debug.print("   æ¯è®¾å¤‡æ—¥å¿—: 10æ¡\n", .{});
    std.debug.print("   æ€»æ—¥å¿—é‡: 1000ä¸‡æ¡\n\n", .{});

    // ========================================
    // æµ‹è¯• 1: é¡ºåºå‹æµ‹ï¼ˆå•çº¿ç¨‹ï¼Œæµ‹é‡çº¯å†™å…¥æ€§èƒ½ï¼‰
    // ========================================
    std.debug.print("ğŸš€ æµ‹è¯• 1: é¡ºåºå‹æµ‹ï¼ˆå•çº¿ç¨‹ï¼‰\n", .{});

    const sequential_count = 100_000; // 10ä¸‡æ¡
    const start_seq = std.time.nanoTimestamp();

    for (0..sequential_count) |i| {
        logger.info("è®¾å¤‡{d}: çŠ¶æ€æ­£å¸¸, æ¸©åº¦: {d}Â°C, å†…å­˜: {d}MB", .{ i, 45 + (i % 20), 256 - (i % 100) });
    }

    const end_seq = std.time.nanoTimestamp();
    const duration_seq_ns = @as(u64, @intCast(end_seq - start_seq));
    const duration_seq_us = duration_seq_ns / std.time.ns_per_us;
    const qps_seq = (sequential_count * std.time.ns_per_s) / duration_seq_ns;
    const latency_seq_ns = duration_seq_ns / sequential_count;

    std.debug.print("   âœ“ å®Œæˆ: {d} æ¡æ—¥å¿—\n", .{sequential_count});
    std.debug.print("   âœ“ è€—æ—¶: {d} Î¼s\n", .{duration_seq_us});
    std.debug.print("   âœ“ QPS: {d} æ¡/ç§’\n", .{qps_seq});
    std.debug.print("   âœ“ å¹³å‡å»¶è¿Ÿ: {d} ns/æ¡ (â‰ˆ {d:.2} Î¼s)\n\n", .{ latency_seq_ns, @as(f64, @floatFromInt(latency_seq_ns)) / 1000.0 });

    // ç­‰å¾…é˜Ÿåˆ—å¤„ç†
    std.debug.print("â³ ç­‰å¾…æ—¥å¿—é˜Ÿåˆ—å¤„ç†...\n", .{});
    std.Thread.sleep(2 * std.time.ns_per_s);

    // ========================================
    // æµ‹è¯• 2: å¤šçº¿ç¨‹å¹¶å‘ï¼ˆæ¨¡æ‹Ÿå¤šè®¾å¤‡å¹¶å‘ä¸ŠæŠ¥ï¼‰
    // ========================================
    std.debug.print("\nğŸš€ æµ‹è¯• 2: å¤šçº¿ç¨‹å¹¶å‘ï¼ˆ{d} çº¿ç¨‹ï¼‰\n", .{16});

    const thread_count = 16;
    const logs_per_thread = 50_000; // æ¯çº¿ç¨‹ 5 ä¸‡æ¡
    const total_logs = thread_count * logs_per_thread; // æ€»å…± 80 ä¸‡æ¡

    var threads: [thread_count]std.Thread = undefined;
    const start_concurrent = std.time.nanoTimestamp();

    // å¯åŠ¨å·¥ä½œçº¿ç¨‹
    for (0..thread_count) |i| {
        threads[i] = try std.Thread.spawn(.{}, workerThread, .{ logger, i, logs_per_thread });
    }

    // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for (threads) |thread| {
        thread.join();
    }

    const end_concurrent = std.time.nanoTimestamp();
    const duration_concurrent_ns = @as(u64, @intCast(end_concurrent - start_concurrent));
    const duration_concurrent_us = duration_concurrent_ns / std.time.ns_per_us;
    const qps_concurrent = (total_logs * std.time.ns_per_s) / duration_concurrent_ns;
    const latency_concurrent_ns = duration_concurrent_ns / total_logs;

    std.debug.print("   âœ“ å®Œæˆ: {d} æ¡æ—¥å¿— ({d} çº¿ç¨‹ Ã— {d})\n", .{ total_logs, thread_count, logs_per_thread });
    std.debug.print("   âœ“ è€—æ—¶: {d} Î¼s ({d:.2} ç§’)\n", .{ duration_concurrent_us, @as(f64, @floatFromInt(duration_concurrent_us)) / 1_000_000.0 });
    std.debug.print("   âœ“ QPS: {d} æ¡/ç§’\n", .{qps_concurrent});
    std.debug.print("   âœ“ å¹³å‡å»¶è¿Ÿ: {d} ns/æ¡ (â‰ˆ {d:.2} Î¼s)\n\n", .{ latency_concurrent_ns, @as(f64, @floatFromInt(latency_concurrent_ns)) / 1000.0 });

    // ç­‰å¾…é˜Ÿåˆ—å®Œå…¨æ¸…ç©º
    std.debug.print("â³ ç­‰å¾…é˜Ÿåˆ—å®Œå…¨å¤„ç†...\n", .{});
    std.Thread.sleep(3 * std.time.ns_per_s);

    // ========================================
    // ç»Ÿè®¡æŠ¥å‘Š
    // ========================================
    std.debug.print("\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:\n", .{});
    std.debug.print("   å·²å¤„ç†: {d} æ¡\n", .{logger.getProcessedCount()});
    std.debug.print("   å·²ä¸¢å¼ƒ: {d} æ¡\n", .{logger.getDroppedCount()});
    std.debug.print("   é˜Ÿåˆ—å‰©ä½™: {d} æ¡\n", .{logger.getQueueSize()});

    const total_sent = sequential_count + total_logs;
    const drop_rate = (@as(f64, @floatFromInt(logger.getDroppedCount())) / @as(f64, @floatFromInt(total_sent))) * 100.0;
    std.debug.print("   ä¸¢å¼ƒç‡: {d:.4}%\n", .{drop_rate});

    // ========================================
    // æ€§èƒ½å¯¹æ¯”
    // ========================================
    std.debug.print("\nğŸ’¡ æ€§èƒ½åˆ†æ:\n", .{});
    std.debug.print("   å•çº¿ç¨‹ QPS: {d} æ¡/ç§’\n", .{qps_seq});
    std.debug.print("   å¤šçº¿ç¨‹ QPS: {d} æ¡/ç§’\n", .{qps_concurrent});
    std.debug.print("   å¹¶å‘åŠ é€Ÿæ¯”: {d:.2}x\n", .{@as(f64, @floatFromInt(qps_concurrent)) / @as(f64, @floatFromInt(qps_seq))});

    if (latency_seq_ns < 1000) {
        std.debug.print("   âœ… å•çº¿ç¨‹å»¶è¿Ÿ < 1Î¼s: æé€Ÿæ¨¡å¼\n", .{});
    } else if (latency_seq_ns < 10_000) {
        std.debug.print("   âœ… å•çº¿ç¨‹å»¶è¿Ÿ < 10Î¼s: ä¼˜ç§€\n", .{});
    } else {
        std.debug.print("   âš ï¸  å•çº¿ç¨‹å»¶è¿Ÿ > 10Î¼s: éœ€ä¼˜åŒ–\n", .{});
    }

    if (drop_rate < 0.1) {
        std.debug.print("   âœ… ä¸¢å¼ƒç‡ < 0.1%%: é˜Ÿåˆ—å®¹é‡å……è¶³\n", .{});
    } else if (drop_rate < 1.0) {
        std.debug.print("   âš ï¸  ä¸¢å¼ƒç‡ < 1%%: è€ƒè™‘å¢åŠ é˜Ÿåˆ—å®¹é‡\n", .{});
    } else {
        std.debug.print("   âŒ ä¸¢å¼ƒç‡ >= 1%%: å¿…é¡»å¢åŠ é˜Ÿåˆ—å®¹é‡æˆ–é™æµ\n", .{});
    }

    std.debug.print("\n=== æµ‹è¯•å®Œæˆ ===\n", .{});
}

/// å·¥ä½œçº¿ç¨‹ï¼šæ¨¡æ‹Ÿè®¾å¤‡ä¸ŠæŠ¥æ—¥å¿—
fn workerThread(logger: *AsyncLogger.AsyncLogger, thread_id: usize, count: usize) void {
    for (0..count) |i| {
        const device_id = thread_id * 1_000_000 + i;
        logger.info("è®¾å¤‡{d}: ä¸ŠæŠ¥æ•°æ®, CPU: {d}%, è¿æ¥: {d}ms", .{
            device_id,
            30 + (i % 70),
            10 + (i % 50),
        });
    }
}
